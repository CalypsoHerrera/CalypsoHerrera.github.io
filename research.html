<!DOCTYPE HTML>
<html>
  <head>
    <title>Calypso Herrera - Research</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
    <link rel="stylesheet" href="assets/css/main.css" />
    <!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
  </head>

  <body class="landing">
    <div id="page-wrapper">
      <header id="header" class="alt">
        <h1><a href="index.html">Calypso Herrera</a>
	 </h1>
        <nav id="nav">
          <ul>
	    <li><a href="index.html">Home</a></li>
            <li><a href="research.html">Research and Talks</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="curriculum.html">Curriculum</a></li>
          </ul>
        </nav>
      </header>


<section id="banner" class="research">
  <h2>Research</h2>
</section>

<section id="main" class="container">
  <section class="box">
    <h3>Publications and Preprints </h3>
        <dl>

<b><a href="https://www.research-collection.ethz.ch/handle/20.500.11850/529739" target="_blank" rel="noopener noreferrer">Doctoral Thesis - Machine Learning in Finance: Applications of Continuous Depth and Randomized Neural Networks </a></b>
<br> Examiner: Prof. Dr. Josef Teichmann  and Co-Examiner: Prof. Dr. Antoine Jacquier
<br> Defended on September 15th, 2021
<br><br>


<b><a href="https://arxiv.org/abs/2104.13669" target="_blank" rel="noopener noreferrer">Optimal Stopping via Randomized Neural Networks</a></b>
<br> Calypso Herrera, Florian Krach, Pierre Ruyssen, Josef Teichmann
<br> Preprint (submitted), 2021  [<a href="https://arxiv.org/abs/2104.13669">paper</a>, <a href="https://github.com/HeKrRuTe/OptStopRandNN">code</a>, <a href= "slides\OptStopRandNN_slides.pdf">slides</a>]
<br><br>


<b><a href="https://arxiv.org/abs/2006.04727" target="_blank" rel="noopener noreferrer">Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering</a></b>
<br> Calypso Herrera, Florian Krach, Josef Teichmann
<br> International Conference on Learning Representations (ICLR), 2021 [<a href="https://arxiv.org/abs/2006.04727" target="_blank" rel="noopener noreferrer">paper</a>, <a href="https://github.com/HerreraKrachTeichmann/NJODE" target="_blank" rel="noopener noreferrer">code</a>]
<br><br>

<b><a href="https://arxiv.org/abs/2004.13612" target="_blank" rel="noopener noreferrer">Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices</a></b>
<br> Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen, Josef Teichmann
<br> Preprint (submitted), 2020 [<a href="https://arxiv.org/abs/2004.13612" target="_blank" rel="noopener noreferrer">paper</a>, <a href="https://github.com/DeepRPCA/Denise" target="_blank" rel="noopener noreferrer">code</a>]
<br><br>

<b><a href="https://arxiv.org/abs/2004.13135" target="_blank" rel="noopener noreferrer">Estimating Full Lipschitz Constants of Deep Neural Networks</a></b>
<br> Calypso Herrera, Florian Krach, Josef Teichmann
<br> Preprint, 2020 [<a href="https://arxiv.org/abs/2004.13135" target="_blank" rel="noopener noreferrer">paper</a>]
<br><br>

<b><a href="https://arxiv.org/abs/1908.00461" target="_blank" rel="noopener noreferrer" >Low-Rank plus Sparse Decomposition of Covariance Matrices using Neural Network Parametrization</a></b>
<br> Michel Baes, Calypso Herrera, Ariel Neufeld, Pierre Ruyssen
<br> Transaction on Neural Networks and Learning systems (accepeted for publication), 2021 [<a href="https://arxiv.org/abs/1908.00461" target="_blank" rel="noopener noreferrer">paper</a>, <a href="https://github.com/CalypsoHerrera/lrs-cov-nn" target="_blank" rel="noopener noreferrer">code</a>]
<br><br>


<b><a href="https://arxiv.org/abs/1404.1180" target="_blank" rel="noopener noreferrer">Parallel American Monte Carlo</a></b>
<br> Calypso Herrera, Louis Paulot
<br> Preprint, 2016 [<a href="https://arxiv.org/abs/1404.1180" target="_blank" rel="noopener noreferrer">paper</a>]

    </dl>

    <dl>
<a href="https://scholar.google.com/citations?user=LPdzJWgAAAAJ&hl=fr" target="_blank" rel="noopener noreferrer">Google Scholar</a> and
<a href="https://github.com/CalypsoHerrera" target="_blank" rel="noopener noreferrer">GitHub</a>

</dl>

  </section>
</section>



<section id="main" class="container">
  <section class="box">
    <h3>Past Talks</h3>
    <dl>
<li><b><a href="https://math.ethz.ch/imsf/events/conferences-and-workshops/past-events/2022/oxford-eth-2022.html" target="_blank" rel="noopener noreferrer">Oxford ETH Workshop, 2022</a></b>, Zurich (Switzerland), 20-21.06.2022. Optimal Stopping via Randomized Neural Networks.</li>


<li><b><a href="https://meetings.siam.org/sess/dsp_programsess.cfm?sessioncode=71751" target="_blank" rel="noopener noreferrer">SIAM Annual Meeting, 2021</a></b>, Virtual, 19-23.07.2021. Optimal Stopping via Randomized Neural Networks.</li>



<li><b><a href="https://events.math.unipd.it/AMAMEF2021/" target="_blank" rel="noopener noreferrer">10th General AMaMeF Conference, 2021</a></b>, Virtual Padova (Italy), 22-25.06.2021. Optimal Stopping via Randomized Neural Networks.</li>
<li><b><a href="https://www.mfo.de/occasion/2044/www_view" target="_blank" rel="noopener noreferrer">Oberwolfach Workshop 2020</a></b>, Virtual Oberwolfach (Germany), 25-21.10.2020. Optimal Stopping via Randomized Neural Networks. </li>
<li><b><a href="https://people.math.ethz.ch/~jteichma/index.php?content=working_group" target="_blank" rel="noopener noreferrer" >Josef's Friday Seminar</a></b>, Virtual Zurich (Switzerland), 01.05.2020. Neural Jump Ordinary Differential Equations: Consistent Continuous-Time Prediction and Filtering.</li>
<li><b><a href="https://people.math.ethz.ch/~jteichma/index.php?content=FWZ_seminar" target="_blank" rel="noopener noreferrer" >FPWZ Seminar</a></b>, Zurich (Switzerland), 10-11.10.2019. Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices.</li>
<li><b><a href="https://people.math.ethz.ch/~jteichma/index.php?content=FWZ_seminar" target="_blank" rel="noopener noreferrer" >FWZ Seminar</a></b>, Padova (Italy), 16-17.05.2019. Low-Rank plus Sparse Decomposition of Covariance Matrices using Neural Network Parametrization.</li>
<li><b><a href="https://people.math.ethz.ch/~jteichma/index.php?content=FWZ_seminar" target="_blank" rel="noopener noreferrer">FWZ Seminar</a></b>, Vienna (Austria), 15-16.01.2018. Parallel American Monte Carlo.</li>
<li><b><a href="http://ykabanov.perso.math.cnrs.fr/Bachelier2017/" target="_blank" rel="noopener noreferrer" >Bachelier Colloquium 2017</a></b>, M&eacute;tabief (France), 16-21.1.2017. Parallel American Monte Carlo.</li>
<li><b><a href="https://people.math.ethz.ch/~jteichma/index.php?content=FWZ_seminar" target="_blank" rel="noopener noreferrer">FWZ Seminar</a></b>, Freiburg (Germany), 30.11-2.12.2016. Parallel American Monte Carlo.</li>
<li><b><a href="https://www.math.ethz.ch/imsf/courses/mf-seminar.html?s=hs16/" target="_blank" rel="noopener noreferrer">Post/Doctoral Seminar in Mathematical Finance</a></b>, Zurich (Switzerland), 25.10.2016. Convexity adjustment on terminal rate models.</li>

<li><b><a href="https://www.math.ethz.ch/imsf/events/conferences-and-workshops/past-events/2016/imperial-eth-2016.html" target="_blank" rel="noopener noreferrer">Imperial ETH Workshop on Mathemetical Finance 2016</a></b>, Zurich (Switzerland), 26-28.10.2016. Parallel American Monte Carlo.</li>

    </dl>
  </section>
</section>

    </div>
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.dropotron.min.js"></script>
    <script src="assets/js/jquery.scrollgress.min.js"></script>
    <script src="assets/js/skel.min.js"></script>
    <script src="assets/js/util.js"></script>
    <!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
    <script src="assets/js/main.js"></script>
  </body>
</html>
